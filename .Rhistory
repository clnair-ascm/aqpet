miss_data_treat = miss_data_treat,
split_proportion = split_proportion,
split_by_time = split_by_time,
seed = seed,
max_models = max_models,
max_runtime_secs = max_runtime_secs,
wenorm_method = wenorm_method,
num_iterations = num_iterations,
algorithm = algorithm,
criterion = criterion,
write_out = write_out,
kill_h2o = kill_h2o,
out_dir = out_dir,
cpd = cpd,
window = window))
}
#' Set Synthetic Control Parameters
#' @param treatment_group A vector of treatment group cities.
#' @param start_time The start time for the analysis.
#' @param end_time The end time for the analysis.
#' @param buffer_time The buffer time for the analysis.
#' @param split_proportion The proportion of data to be used for training.
#' @param split_by_time Logical, whether to split data by time.
#' @param seed The seed for reproducibility.
#' @param max_models The maximum number of models to be trained.
#' @param max_runtime_secs The maximum runtime in seconds.
#' @param algorithm The machine learning algorithm to be used.
#' @param criterion The criterion for model selection.
#' @return A list of Synthetic Control Panel parameters.
setSCP <- function(treatment_group = c("Marylebone"),
start_time = c("2018-09-01"),
end_time = c("2018-09-15"),
buffer_time = NULL,
split_proportion = 0.8,
split_by_time = FALSE,
seed = 123,
max_models = 7,
max_runtime_secs = 120,
algorithm = "gbm",
criterion = "AUTO") {
return(list(treatment_group = treatment_group,
start_time = start_time,
end_time = end_time,
buffer_time = buffer_time,
split_proportion = split_proportion,
split_by_time = split_by_time,
seed = seed,
max_models = max_models,
max_runtime_secs = max_runtime_secs,
algorithm = algorithm,
criterion = criterion))
}
number_data = c(2,1)
#'
###################################################################################################################################################################
#'
# ---- Global_Control_Panel ----
#'
Global_Control_Panel     <- list(
data_dir           = "E:/UoB_2022_2024/4_aqpet_r/AQPET/data",
file_pattern       = "*.csv",
datetime_format    = "%d/%m/%Y %H:%M",
dependent_variable = "no2",
data_timerange     = c("2018-01-01", "2019-12-31"),
wenormed        = F
)
#'
###################################################################################################################################################################
#'
# ---- Global_Control_Panel ----
#'
Global_Control_Panel     <- list(
data_dir           = "E:/UoB_2022_2024/4_aqpet_r/AQPET/data",
file_pattern       = "*.csv",
datetime_format    = "%d/%m/%Y %H:%M",
dependent_variable = "no2",
data_timerange     = c("2018-01-01", "2019-12-31"),
wenormed        = F
)
#'
##################################################################################################################################################################
#' Run the script
#'
data_pretreated <- read_data(Global_Control_Panel)
devtools::use_data(data_pretreated, aqpet)
install.packages("usethis")
library(usethis)
devtools::use_data(data_pretreated, aqpet)
use_data(data_pretreated, aqpet)
use_data(data_pretreated, overwrite = T)
#' Set Global Parameters
#' @param data_dir The directory where the data files are stored.
#' @param file_pattern The pattern to match for data files.
#' @param datetime_format The format of the datetime in the data files.
#' @param dependent_variable The dependent variable in the analysis.
#' @param data_timerange The time range for the analysis.
#' @param wenormed Logical, whether the data is weather-normalized.
#' @return A list of Global Control Panel parameters.
setGP <- function(data_dir = ".",
file_pattern = "*.csv",
datetime_format = "%d/%m/%Y %H:%M",
dependent_variable = "no2",
data_timerange = c("2018-01-01", "2019-12-31"),
wenormed = FALSE) {
return(list(data_dir = data_dir,
file_pattern = file_pattern,
datetime_format = datetime_format,
dependent_variable = dependent_variable,
data_timerange = data_timerange,
wenormed = wenormed))
}
#' Set Weather Normalization Parameters
#' @param response_variable The response variable in the analysis.
#' @param predictor_variables A vector of predictor variables.
#' @param constant_variables A vector of constant variables.
#' @param miss_data_treat The method to treat missing data.
#' @param split_proportion The proportion of data to be used for training.
#' @param split_by_time Logical, whether to split data by time.
#' @param seed The seed for reproducibility.
#' @param max_models The maximum number of models to be trained.
#' @param max_runtime_secs The maximum runtime in seconds.
#' @param wenorm_method The method for weather normalization.
#' @param num_iterations The number of iterations for training.
#' @param algorithm The machine learning algorithm to be used.
#' @param criterion The criterion for model selection.
#' @param write_out Logical, whether to write out the results.
#' @param kill_h2o Logical, whether to shut down the H2O cluster.
#' @param out_dir The output directory.
#' @param cpd Logical, whether to use change point detection.
#' @param window The window size for the analysis.
#' @return A list of Weather Normalized Panel parameters.
setWeNorm <- function(response_variable = "no2",
predictor_variables = c("trend", "month", "day", "dow", "doy", "hour", "wd", "ws", "RH", "temp", "sp", "blh"),
constant_variables = c("wd", "ws", "RH", "temp", "sp", "blh"),
miss_data_treat = "rm",
split_proportion = 0.8,
split_by_time = FALSE,
seed = 123,
max_models = 10,
max_runtime_secs = 120,
wenorm_method = "revised",
num_iterations = 300,
algorithm = "gbm",
criterion = "AUTO",
write_out = TRUE,
kill_h2o = FALSE,
out_dir = "revised_",
cpd = TRUE,
window = 50) {
return(list(response_variable = response_variable,
predictor_variables = predictor_variables,
constant_variables = constant_variables,
miss_data_treat = miss_data_treat,
split_proportion = split_proportion,
split_by_time = split_by_time,
seed = seed,
max_models = max_models,
max_runtime_secs = max_runtime_secs,
wenorm_method = wenorm_method,
num_iterations = num_iterations,
algorithm = algorithm,
criterion = criterion,
write_out = write_out,
kill_h2o = kill_h2o,
out_dir = out_dir,
cpd = cpd,
window = window))
}
#' Set Synthetic Control Parameters
#' @param treatment_group A vector of treatment group cities.
#' @param start_time The start time for the analysis.
#' @param end_time The end time for the analysis.
#' @param buffer_time The buffer time for the analysis.
#' @param split_proportion The proportion of data to be used for training.
#' @param split_by_time Logical, whether to split data by time.
#' @param seed The seed for reproducibility.
#' @param max_models The maximum number of models to be trained.
#' @param max_runtime_secs The maximum runtime in seconds.
#' @param algorithm The machine learning algorithm to be used.
#' @param criterion The criterion for model selection.
#' @return A list of Synthetic Control Panel parameters.
setSCP <- function(treatment_group = c("Marylebone"),
start_time = c("2018-09-01"),
end_time = c("2018-09-15"),
buffer_time = NULL,
split_proportion = 0.8,
split_by_time = FALSE,
seed = 123,
max_models = 7,
max_runtime_secs = 120,
algorithm = "gbm",
criterion = "AUTO") {
return(list(treatment_group = treatment_group,
start_time = start_time,
end_time = end_time,
buffer_time = buffer_time,
split_proportion = split_proportion,
split_by_time = split_by_time,
seed = seed,
max_models = max_models,
max_runtime_secs = max_runtime_secs,
algorithm = algorithm,
criterion = criterion))
}
#' Read Data From Specified Directory and Process It
#'
#' This function reads multiple data files from a specified directory, processes them,
#' and optionally writes the processed data to a CSV file. The function supports both
#' CSV and XLSX file formats.
#'
#' @param params A named list containing various parameters:
#'   - `data_dir`: The directory containing data files.
#'   - `file_pattern`: A regex pattern to match specific files within the directory.
#'   - `datetime_format`: The format of the datetime column in the files.
#'   - `data_timerange`: A vector of two Date elements specifying the range of dates to filter the data.
#'   - `dependent_variable`: The name of the dependent variable in the dataset.
#'   - `wenormed`: A logical value indicating whether to modify the dependent variable name with a "_wn" suffix.
#'
#' @param write_out A logical. If TRUE, writes the processed data to a file named "df_origin.csv".
#' Defaults to FALSE.
#' @param ... Additional arguments (currently not used).
#'
#' @details
#' The function first gets a list of filenames matching the given pattern in the directory.
#' It then reads each file, processes the datetime column, filters rows based on the given date range,
#' adds additional date-related columns, and ensures that the dependent variable is numeric.
#' If the `deweathered` parameter is TRUE, it modifies the dependent variable name by adding a "_wn" suffix.
#' Finally, it optionally writes the processed data to a CSV file if `write_out` is TRUE.
#'
#' @return A list containing:
#'   - `list_df`: A named list of data frames, where each data frame corresponds to a file and
#'     the name is the filename without the extension.
#'   - `df_origin`: A combined data frame derived from `list_df`.
#'
#' @author [Yuqing Dai]
#'
#' @examples
#' \dontrun{
#' params <- list(
#'     data_dir = "path/to/data/",
#'     file_pattern = "*.csv",
#'     datetime_format = "%Y-%m-%d %H:%M:%S",
#'     data_timerange = as.Date(c("2022-01-01", "2022-12-31")),
#'     dependent_variable = "target",
#'     deweathered = FALSE
#' )
#'
#' result <- read_data(params)
#' head(result$df_origin)
#' }
#'
#' @export
#'
read_data <- function(params,
write_out = FALSE,
...) {
# Correct directory separator
params$data_dir <- gsub("\\\\", "/", params$data_dir)
# Get list of files matching the pattern
filenames <- list.files(
path = params$data_dir,
pattern = params$file_pattern,
full.names = TRUE
)
require(readxl)
list_df <- setNames(lapply(filenames, function(x) {
extension <- tools::file_ext(x)
if (extension == "csv") {
df <- read_csv(x)
} else if (extension == "xlsx") {
df <- read_excel(x)
} else {
stop("Unsupported file type")
}
df$datetime <- as.POSIXct(df$datetime, format = params$datetime_format)
df <- df[as.Date(df$datetime) >= as.Date(params$data_timerange[1]) & as.Date(df$datetime) <= as.Date(params$data_timerange[2]), ]
df <- df[complete.cases(df$datetime), ]
df <- add_date_cols(df, date_col = datetime, stats = "all")
df
}), tools::file_path_sans_ext(basename(filenames)))
# If 'wenormed', modify dependent variable name
if (params$wenormed) {
params$dependent_variable <- paste0(params$dependent_variable, "_wn")
}
# Filter out data frames where dependent variable is entirely NA
list_df <- list_df[!sapply(list_df, function(df) {
all(is.na(df[[params$dependent_variable]]))
})]
# Ensure dependent variable is numeric
list_df <- lapply(list_df, function(df) {
df[[params$dependent_variable]] <- as.numeric(df[[params$dependent_variable]])
return(df)
})
list_df2 <- list2df_xyselect(list_df, colnames = params$dependent_variable)
# Write output if required
if (write_out) {
write.csv(list_df2, "df_origin.csv")
}
return(list(list_df = list_df, df_origin = list_df2))
}
#' Read Data From Specified Directory and Process It
#'
#' This function reads multiple data files from a specified directory, processes them,
#' and optionally writes the processed data to a CSV file. The function supports both
#' CSV and XLSX file formats.
#'
#' @param params A named list containing various parameters:
#'   - `data_dir`: The directory containing data files.
#'   - `file_pattern`: A regex pattern to match specific files within the directory.
#'   - `datetime_format`: The format of the datetime column in the files.
#'   - `data_timerange`: A vector of two Date elements specifying the range of dates to filter the data.
#'   - `dependent_variable`: The name of the dependent variable in the dataset.
#'   - `wenormed`: A logical value indicating whether to modify the dependent variable name with a "_wn" suffix.
#'
#' @param write_out A logical. If TRUE, writes the processed data to a file named "df_origin.csv".
#' Defaults to FALSE.
#' @param ... Additional arguments (currently not used).
#'
#' @details
#' The function first gets a list of filenames matching the given pattern in the directory.
#' It then reads each file, processes the datetime column, filters rows based on the given date range,
#' adds additional date-related columns, and ensures that the dependent variable is numeric.
#' If the `wenormed` parameter is TRUE, it modifies the dependent variable name by adding a "_wn" suffix.
#' Finally, it optionally writes the processed data to a CSV file if `write_out` is TRUE.
#'
#' @return A list containing:
#'   - `list_df`: A named list of data frames, where each data frame corresponds to a file and
#'     the name is the filename without the extension.
#'   - `df_origin`: A combined data frame derived from `list_df`.
#'
#' @author [Yuqing Dai]
#'
#' @examples
#' \dontrun{
#' params <- list(
#'     data_dir = "path/to/data/",
#'     file_pattern = "*.csv",
#'     datetime_format = "%Y-%m-%d %H:%M:%S",
#'     data_timerange = as.Date(c("2022-01-01", "2022-12-31")),
#'     dependent_variable = "target",
#'     deweathered = FALSE
#' )
#'
#' result <- read_data(params)
#' head(result$df_origin)
#' }
#'
#' @export
#'
read_data <- function(params,
write_out = FALSE,
...) {
# Correct directory separator
params$data_dir <- gsub("\\\\", "/", params$data_dir)
# Get list of files matching the pattern
filenames <- list.files(
path = params$data_dir,
pattern = params$file_pattern,
full.names = TRUE
)
require(readxl)
list_df <- setNames(lapply(filenames, function(x) {
extension <- tools::file_ext(x)
if (extension == "csv") {
df <- read_csv(x)
} else if (extension == "xlsx") {
df <- read_excel(x)
} else {
stop("Unsupported file type")
}
df$datetime <- as.POSIXct(df$datetime, format = params$datetime_format)
df <- df[as.Date(df$datetime) >= as.Date(params$data_timerange[1]) & as.Date(df$datetime) <= as.Date(params$data_timerange[2]), ]
df <- df[complete.cases(df$datetime), ]
df <- add_date_cols(df, date_col = datetime, stats = "all")
df
}), tools::file_path_sans_ext(basename(filenames)))
# If 'wenormed', modify dependent variable name
if (params$wenormed) {
params$dependent_variable <- paste0(params$dependent_variable, "_wn")
}
# Filter out data frames where dependent variable is entirely NA
list_df <- list_df[!sapply(list_df, function(df) {
all(is.na(df[[params$dependent_variable]]))
})]
# Ensure dependent variable is numeric
list_df <- lapply(list_df, function(df) {
df[[params$dependent_variable]] <- as.numeric(df[[params$dependent_variable]])
return(df)
})
list_df2 <- list2df_xyselect(list_df, colnames = params$dependent_variable)
# Write output if required
if (write_out) {
write.csv(list_df2, "df_origin.csv")
}
return(list(list_df = list_df, df_origin = list_df2))
}
GP <- setGP()
data <- read_data(GP)
#' Combine Selected Columns from List of Data Frames
#'
#' This function processes a list of data frames and consolidates them based on the specified columns.
#' The data frames in the list are expected to contain a 'datetime' column, and they are merged by this column.
#'
#' @param df_list A list of data frames to be combined.
#' @param colnames Character vector specifying the column names to extract from each data frame in the list. Default is 'y'.
#' @param time_resolution Optional: A time resolution for aggregating data. Valid values might include "minute", "hour", "day", etc.
#'
#' @return Returns a consolidated data frame.
#'
#' @author [Yuqing Dai]
#'
#' @examples
#' \dontrun{
#' data1 <- data.frame(datetime = as.POSIXct(c("2021-01-01", "2021-01-02")), y = c(1,2))
#' data2 <- data.frame(datetime = as.POSIXct(c("2021-01-01", "2021-01-02")), y = c(3,4))
#' mylist <- list(df1 = data1, df2 = data2)
#'
#' combined_df <- list2df_xyselect(mylist, colnames = "y")
#' print(combined_df)
#' }
#'
#' @export
#'
list2df_xyselect <- function(df_list, colnames = "y", time_resolution = NULL) {
# Check if the dataframe list is empty
if (length(df_list) == 0) stop("The list of dataframes is empty.")
# Initialize an empty dataframe to hold the merged selected columns
merged_df <- data.frame()
for(i in seq_along(df_list)) {
if (!"datetime" %in% names(df_list[[i]])) stop("No 'datetime' column in dataframe", names(df_list)[i], ".")
for (colname in colnames) {
# Check if the selected column exists in the dataframe
if (!(colname %in% names(df_list[[i]]))) {
warning(paste("Column", colname, "not found in dataframe", names(df_list)[i], ". Skipping this dataframe."))
next
}
# Extract the 'datetime' and selected column
temp_df <- df_list[[i]][, c("datetime", colname)]
# Rename the selected column to the column name plus the name of the dataframe
names(temp_df)[names(temp_df) == colname] <- paste0(colname, "_", names(df_list)[i])
# If a time resolution has been specified, aggregate the data accordingly
if (!is.null(time_resolution)) {
temp_df$datetime <- as.POSIXct(temp_df$datetime)
temp_df <- temp_df %>%
mutate(datetime = floor_date(datetime, time_resolution)) %>%
group_by(datetime) %>%
summarise(across(everything(), mean, na.rm = TRUE))
}
# Merge the current dataframe with the merged_df by 'datetime'
merged_df <- if (nrow(merged_df) == 0) {
temp_df
} else {
merge(merged_df, temp_df, by = "datetime", all = TRUE)
}
}
}
return(merged_df)
}
data <- read_data(GP)
#'
###################################################################################################################################################################
#'
# ---- Global_Control_Panel ----
#'
Global_Control_Panel     <- list(
data_dir           = "E:/UoB_2022_2024/4_aqpet_r/AQPET/data",
file_pattern       = "*.csv",
datetime_format    = "%d/%m/%Y %H:%M",
dependent_variable = "no2",
data_timerange     = c("2018-01-01", "2019-12-31"),
wenormed        = F
)
View(Global_Control_Panel)
View(GP)
View(Global_Control_Panel)
data <- read_data(Global_Control_Panel)
#'
sapply(list.files(path <- "E:/UoB_2022_2024/4_aqpet_r/AQPET/AQPET_R/R/", full.names = TRUE, pattern = "*.R$"), source)
data <- read_data(Global_Control_Panel)
devtools::use_data(data, aqpet)
use_data(data, aqpet)
use_data(data, overwrite = T)
data_preWeNorm <- read_data(Global_Control_Panel)
use_data(data_preWeNorm, overwrite = T)
View(data_preWeNorm)
devtools::use_vignette("aqpet-tutorial")
use_vignette("aqpet-tutorial")
usethis::use_package("bcp")
usethis::use_package("bsts")
usethis::use_package("changepoint")
usethis::use_package("devtools")
usethis::use_package("doParallel")
usethis::use_package("dplyr")
usethis::use_package("foreach")
usethis::use_package("h2o")
usethis::use_package("lubridate")
usethis::use_package("magrittr")
usethis::use_package("openair")
usethis::use_package("plot3Drgl")
usethis::use_package("purrr")
usethis::use_package("readxl")
usethis::use_package("rgl")
usethis::use_package("rsample")
usethis::use_package("tidymodels")
usethis::use_package("tidymodels", type = "depends")
usethis::use_package("tidyverse")
usethis::use_package("tidyverse", type = "depends")
usethis::use_package("zoo")
usethis::use_package("magrittr")
usethis::use_package("agua")
usethis::use_package("augsynth")
devtools::build_vignettes()
